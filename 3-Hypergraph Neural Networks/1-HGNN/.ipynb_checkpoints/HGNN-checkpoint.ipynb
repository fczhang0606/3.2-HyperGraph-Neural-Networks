{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d8091-a389-4a5e-bd02-455804239760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dhg import Graph, Hypergraph\n",
    "from dhg.data import Cora\n",
    "from dhg.models import HGNN\n",
    "from dhg.random import set_seed\n",
    "from dhg.metrics import HypergraphVertexClassificationEvaluator as Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80186ec0-1281-42cc-99f8-b50c04c4be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X, G, lbls, train_idx, optimizer, epoch):\n",
    "    net.train()\n",
    "\n",
    "    st = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    outs = net(X, G)\n",
    "    outs, lbls = outs[train_idx], lbls[train_idx]\n",
    "    loss = F.cross_entropy(outs, lbls)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Time: {time.time()-st:.5f}s, Loss: {loss.item():.5f}\")\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer(net, X, G, lbls, idx, test=False):\n",
    "    net.eval()\n",
    "    outs = net(X, G)\n",
    "    outs, lbls = outs[idx], lbls[idx]\n",
    "    if not test:\n",
    "        res = evaluator.validate(lbls, outs)\n",
    "    else:\n",
    "        res = evaluator.test(lbls, outs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce6653-0493-4725-a32f-76e0680e3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2022)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "evaluator = Evaluator([\"accuracy\", \"f1_score\", {\"f1_score\": {\"average\": \"micro\"}}])\n",
    "data = Cora()\n",
    "X, lbl = data[\"features\"], data[\"labels\"]\n",
    "G = Graph(data[\"num_vertices\"], data[\"edge_list\"])\n",
    "HG = Hypergraph.from_graph_kHop(G, k=1)\n",
    "train_mask = data[\"train_mask\"]\n",
    "val_mask = data[\"val_mask\"]\n",
    "test_mask = data[\"test_mask\"]\n",
    "\n",
    "net = HGNN(data[\"dim_features\"], 16, data[\"num_classes\"])\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "X, lbl = X.to(device), lbl.to(device)\n",
    "HG = HG.to(device)\n",
    "net = net.to(device)\n",
    "\n",
    "best_state = None\n",
    "best_epoch, best_val = 0, 0\n",
    "train_loss = []\n",
    "valid_acc = []\n",
    "for epoch in range(300):\n",
    "    # train\n",
    "    loss = train(net, X, HG, lbl, train_mask, optimizer, epoch)\n",
    "    train_loss.append(loss)\n",
    "    # validation\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            val_res = infer(net, X, HG, lbl, val_mask)\n",
    "            valid_acc.append(val_res)\n",
    "        if val_res > best_val:\n",
    "            print(f\"update best: {val_res:.5f}\")\n",
    "            best_epoch = epoch\n",
    "            best_val = val_res\n",
    "            best_state = deepcopy(net.state_dict())\n",
    "print(\"\\ntrain finished!\")\n",
    "print(f\"best val: {best_val:.5f}\")\n",
    "# test\n",
    "print(\"test...\")\n",
    "net.load_state_dict(best_state)\n",
    "res = infer(net, X, HG, lbl, test_mask, test=True)\n",
    "print(f\"final result: epoch: {best_epoch}\")\n",
    "print(res)\n",
    "\n",
    "plt.plot(range(300), train_loss)\n",
    "plt.plot(range(300), valid_acc)\n",
    "plt.legend(['train_loss', 'valid_acc'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
